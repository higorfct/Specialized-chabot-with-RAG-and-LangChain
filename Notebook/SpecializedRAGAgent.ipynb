{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "suEDRDV2WbCx" },
      "outputs": [],
      "source": [
        "# Install necessary libraries for Langchain, OpenAI embeddings, FAISS, and PDF loading\n",
        "!pip install langchain==0.3.24 langchain-community==0.3.23 langchain-core==0.3.56 langchain-openai==0.3.14 faiss-cpu==1.11.0 pypdf==5.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "0l8sBX5jXF4X" },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import os\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "93J-uT-eYUb4" },
      "outputs": [],
      "source": [
        "# Set the OpenAI API key as an environment variable\n",
        "OPENAI_API_KEY = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "VHmqzcD9Y6jS" },
      "outputs": [],
      "source": [
        "# Load the PDF document using PyPDFLoader\n",
        "loader = PyPDFLoader(\"fintech_manual.pdf\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "2Naq4aIzYlsG" },
      "outputs": [],
      "source": [
        "# Create OpenAI embeddings and build a FAISS vector store from the loaded documents\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "k2A6fvHYZsbh" },
      "outputs": [],
      "source": [
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(model='gpt-4o', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "e9dTP41saByA" },
      "outputs": [],
      "source": [
        "# Define the system message for the chatbot's persona\n",
        "system_message = SystemMessage(content='''\n",
        "You are a virtual assistant specialized in customer service for Fintech Financial Products.\n",
        "Clearly answer questions about credit card products, investment products, getting started, security and compliance, and customer support.\n",
        "If the question is irrelevant, respond politely by refusing the question.\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "kiBRiz4natUg" },
      "outputs": [],
      "source": [
        "# In-memory storage for chat history\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=chat,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=False\n",
        ")\n",
        "\n",
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    qa_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"chat_history\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "Oeml0iDwdbTn" },
      "outputs": [],
      "source": [
        "# Start an interactive chat session\n",
        "session_id = \"session1\"\n",
        "while True:\n",
        "    question = input(\"You: \")\n",
        "    if question.lower() in [\"exit\", \"quit\", \"sair\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    response = chain_with_history.invoke(\n",
        "        {\"question\": question},\n",
        "        config={\"configurable\": {\"session_id\": session_id}}\n",
        "    )\n",
        "    print(\"Assistant:\", response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "1U8NfVie-YEw" },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
